{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cOMBkFKn6uEK"
   },
   "source": [
    "# Topic Modeling (Prepare)\n",
    "\n",
    "On Monday we talked about summarizing your documents using just token counts. Today, we're going to learn about a much more sophisticated approach - learning 'topics' from documents. Topics are a latent structure. They are not directly observable in the data, but we know they're there by reading them.\n",
    "\n",
    "> **latent**: existing but not yet developed or manifest; hidden or concealed.\n",
    "\n",
    "## Use Cases\n",
    "Primary use case: what the hell are your documents about? Who might want to know that in industry - \n",
    "* Identifying common themes in customer reviews\n",
    "* Discovering the needle in a haystack \n",
    "* Monitoring communications (Email - State Department) \n",
    "\n",
    "## Learning Objectives\n",
    "*At the end of the lesson you should be able to:*\n",
    "* Part 0: Warm-Up\n",
    "* Part 1: Describe how an LDA Model works\n",
    "* Part 2: Estimate a LDA Model with Gensim\n",
    "* Part 3: Interpret LDA results & Select the appropriate number of topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cxH0cRGX6uEL"
   },
   "source": [
    "# Part 0: Warm-Up\n",
    "How do we do a grid search? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FFjplZ7r3Lyk"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sahmj\\anaconda3\\envs\\U4-S1-NLP\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rnyNg8sQ6uEL"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "boKWVkRz6uEO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Samples: 11314\n",
      "Testing Samples: 7532\n"
     ]
    }
   ],
   "source": [
    "# Load training data\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', \n",
    "                                      remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "# Load testing data\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', \n",
    "                                     remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "print(f'Training Samples: {len(newsgroups_train.data)}')\n",
    "print(f'Testing Samples: {len(newsgroups_test.data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hPpukADi7Ofv"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g9Jhb3j-7_e2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train['target_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JbVoIoMm8HbR"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Anybody seen mouse cursor distortion running the Diamond 1024x768x256 driver?\\nSorry, don't know the version of the driver (no indication in the menus) but it's a recently\\ndelivered Gateway system.  Am going to try the latest drivers from Diamond BBS but wondered\\nif anyone else had seen this.\\n\\npost or email\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train['data'][1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w-39zg9a6uEQ"
   },
   "source": [
    "### GridSearch on Just Classifier\n",
    "* Fit the vectorizer and prepare BEFORE it goes into the gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2q3NmHEo6uEQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11314, 101631)\n"
     ]
    }
   ],
   "source": [
    "# Instantiate vectorizer\n",
    "vect = TfidfVectorizer()\n",
    "\n",
    "# Transform the training data\n",
    "X_train = vect.fit_transform(newsgroups_train.data)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7OfA7KNQ6uEU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 out of  20 | elapsed:  1.5min remaining:    9.6s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                              class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              max_samples=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'min_samples_leaf': [1, 2, 5, 10]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_1 = {\n",
    "    'min_samples_leaf': [1, 2, 5, 10]\n",
    "}\n",
    "\n",
    "# Instantiate classifier\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "# GridSearch\n",
    "gs1 = GridSearchCV(clf, params_1, cv=5, n_jobs=-1, verbose=1)\n",
    "gs1.fit(X_train, newsgroups_train['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6574153539838395"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min_samples_leaf': 2}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gDkMaXvG83Zt"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 101631)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sample = vect.transform([\"The new york yankees are the best team in the region.\"])\n",
    "test_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cMq_hw5W6uEX"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Category number\n",
    "gs1.predict(test_sample)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rec.sport.baseball'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Category name\n",
    "newsgroups_train['target_names'][9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WdVTuXKl6uEZ"
   },
   "source": [
    "### GridSearch with BOTH the Vectoizer & Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "97TjUtoI6uEZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('vect',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_words=None,\n",
       "                                                        strip_acce...\n",
       "                                                               min_samples_split=2,\n",
       "                                                               min_weight_fraction_leaf=0.0,\n",
       "                                                               n_estimators=100,\n",
       "                                                               n_jobs=None,\n",
       "                                                               oob_score=False,\n",
       "                                                               random_state=42,\n",
       "                                                               verbose=0,\n",
       "                                                               warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'clf__max_depth': (10, None), 'vect__min_df': (2, 5),\n",
       "                         'vect__stop_words': (None, 'english')},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# 1. Create a pipeline with a vectorize and a classifier\n",
    "# 2. Use Grid Search to optimize the entire pipeline\n",
    "pipe = Pipeline([\n",
    "    ('vect', TfidfVectorizer()),\n",
    "    ('clf', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "params_2 = {\n",
    "    'vect__stop_words': (None, 'english'),\n",
    "    'vect__min_df': (2, 5),\n",
    "    'clf__max_depth': (10, None)\n",
    "}\n",
    "\n",
    "gs2 = GridSearchCV(pipe, params_2, cv=5, n_jobs=-1, verbose=1)\n",
    "gs2.fit(newsgroups_train['data'], newsgroups_train['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6607746264533867"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__max_depth': None, 'vect__min_df': 2, 'vect__stop_words': 'english'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IdIE67Us6uEc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = gs2.predict([\"The new york yankees are the best team in the region.\"])\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xhcb5G0W-Dch"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rec.sport.baseball'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train['target_names'][pred[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F2R2ACd36uEd"
   },
   "source": [
    "Advantages to using GS with the Pipe:\n",
    "* Allows us to make predictions on raw text increasing reproducibility. :)\n",
    "* Allows us to tune the parameters of the vectorizer along side the classifier. :D "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xbZjG6U86uEe"
   },
   "source": [
    "# Part 1: Describe how an LDA Model works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dMzU-XOM3LzW"
   },
   "source": [
    "[Your Guide to Latent Dirichlet Allocation](https://medium.com/@lettier/how-does-lda-work-ill-explain-using-emoji-108abf40fa7d)\n",
    "\n",
    "[LDA Topic Modeling](https://lettier.com/projects/lda-topic-modeling/)\n",
    "\n",
    "[Topic Modeling with Gensim](https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yPIlE_IeF0cX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Download and installation successful\n",
      "You can now load the model via spacy.load('en_core_web_lg')\n"
     ]
    }
   ],
   "source": [
    "# Download spacy model\n",
    "import spacy.cli\n",
    "spacy.cli.download(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qapChu_UGBFc"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "import spacy\n",
    "import pyLDAvis  # Will break jupyter lab\n",
    "import pyLDAvis.gensim \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qaMsy1XAGLxc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11314, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sahmj\\anaconda3\\envs\\U4-S1-NLP\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    'content': newsgroups_train['data'],\n",
    "    'target': newsgroups_train['target'],\n",
    "    'target_names': [newsgroups_train['target_names'][i] for i in newsgroups_train['target']]\n",
    "})\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sahmj\\anaconda3\\envs\\U4-S1-NLP\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>target</th>\n",
       "      <th>target_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>\\nEssential tremor is a progressive hereditary tremor that gets worse\\nwhen the patient tries to use the effected member.  All limbs, vocal\\ncords, and head can be involved.  Inderal is a beta-blocker and\\nis usually effective in diminishing the tremor.  Alcohol and mysoline\\nare also effective, but alcohol is too toxic to use as a treatment.\\n-- \\n----------------------------------------------------------------------------\\nGordon Banks  N3JXP      | \"Skepticism is the chastity of the intellect, and\\ngeb@cadre.dsl.pitt.edu   |  it is shameful to surrender it too soon.\"</td>\n",
       "      <td>13</td>\n",
       "      <td>sci.med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210</th>\n",
       "      <td>\\n\\nI recommend the book \"Adams _v_ Texas\", the story of a man (Adams) who\\nwas sentenced to death for a crime he didn't commit.  Most of the book\\nis the story of the long appeals process, and the problems and delays\\ncaused by not being able to introduce new evidence in certain courts.\\n</td>\n",
       "      <td>18</td>\n",
       "      <td>talk.politics.misc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5309</th>\n",
       "      <td>\\nGlad to hear this, just a note, Osiris, Mithras and many other\\ncult gods resurrected as well, so there's a good chance for all of\\nus to maybe end up in a virtual reality simulator, and live forever,\\nhurrah!\\n\\nSorry, this was a joke, some sort of one anyway. I'm the first\\nthat connected Osiris with a virtual reality personality database.\\nTime to write a book.\\n\\n\\nCheers,\\nKent</td>\n",
       "      <td>19</td>\n",
       "      <td>talk.religion.misc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                content  \\\n",
       "998   \\nEssential tremor is a progressive hereditary tremor that gets worse\\nwhen the patient tries to use the effected member.  All limbs, vocal\\ncords, and head can be involved.  Inderal is a beta-blocker and\\nis usually effective in diminishing the tremor.  Alcohol and mysoline\\nare also effective, but alcohol is too toxic to use as a treatment.\\n-- \\n----------------------------------------------------------------------------\\nGordon Banks  N3JXP      | \"Skepticism is the chastity of the intellect, and\\ngeb@cadre.dsl.pitt.edu   |  it is shameful to surrender it too soon.\"    \n",
       "1210  \\n\\nI recommend the book \"Adams _v_ Texas\", the story of a man (Adams) who\\nwas sentenced to death for a crime he didn't commit.  Most of the book\\nis the story of the long appeals process, and the problems and delays\\ncaused by not being able to introduce new evidence in certain courts.\\n                                                                                                                                                                                                                                                                                                  \n",
       "5309  \\nGlad to hear this, just a note, Osiris, Mithras and many other\\ncult gods resurrected as well, so there's a good chance for all of\\nus to maybe end up in a virtual reality simulator, and live forever,\\nhurrah!\\n\\nSorry, this was a joke, some sort of one anyway. I'm the first\\nthat connected Osiris with a virtual reality personality database.\\nTime to write a book.\\n\\n\\nCheers,\\nKent                                                                                                                                                                                                 \n",
       "\n",
       "      target        target_names  \n",
       "998   13      sci.med             \n",
       "1210  18      talk.politics.misc  \n",
       "5309  19      talk.religion.misc  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 0)\n",
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "na2bkOcFGter"
   },
   "outputs": [],
   "source": [
    "# For reference on regex: https://docs.python.org/3/library/re.html\n",
    "\n",
    "# From 'content' column: \n",
    "\n",
    "    # 1. Remove new line characters\n",
    "df['clean_text'] = df['content'].apply(lambda x: re.sub('\\s+', ' ', x))\n",
    "\n",
    "    # 2. Remove Emails\n",
    "df['clean_text'] = df['content'].apply(lambda x: re.sub('From: \\S+@\\S+', '', x))\n",
    "    \n",
    "    # 3. Remove non-alphanumeric characters\n",
    "df['clean_text'] = df['content'].apply(lambda x: re.sub('[^a-zA-z]', ' ', x))  \n",
    "\n",
    "    # 4. Remove extra whitespace \n",
    "df['clean_text'] = df['content'].apply(lambda x: ' '.join(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2prKILFo3Lzg"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>target</th>\n",
       "      <th>target_names</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11241</th>\n",
       "      <td>I heard FASTMicro went out of business.  Is this true?  \\nThey don't answer their 800 number.  It's 800-821-9000.\\n</td>\n",
       "      <td>3</td>\n",
       "      <td>comp.sys.ibm.pc.hardware</td>\n",
       "      <td>I heard FASTMicro went out of business. Is this true? They don't answer their 800 number. It's 800-821-9000.</td>\n",
       "      <td>[    , hear, FASTMicro, go, business,  , true,  \\n, answer, 800, number,  , 800, 821, 9000, \\n]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9167</th>\n",
       "      <td>\\n\\nThe down side is that when I'm in my cage, I have on numerous occasions\\nslammed my hand into the rolled up window in an effort to wave at\\na passing biker.  Ow.\\n</td>\n",
       "      <td>8</td>\n",
       "      <td>rec.motorcycles</td>\n",
       "      <td>The down side is that when I'm in my cage, I have on numerous occasions slammed my hand into the rolled up window in an effort to wave at a passing biker. Ow.</td>\n",
       "      <td>[\\n\\n, cage, numerous, occasion, \\n, slam, hand, roll, window, effort, wave, \\n, pass, biker,  , ow, \\n]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1461</th>\n",
       "      <td>\\n  Ah, so you finally found a use for that super slo-mo and frame advance\\nother than scrutinizing \"Sorority Babes in Heat\". Congrats! \\n\\n\\n  Trust me, you'd have a helluva time manipulating them. Besides, if you\\nconverted the film to video you'd have all kinds of artifacts because of the\\ndifference in frame rate (unless you're an expert at doing 3/2 pulldown for\\na laserdisc company or something). \\n\\n\\n  Hey, no fair! What about 'Fettucine' Alfredo Griffin? The guy practically\\nhas to pivot the bat around along with his body. \\n\\n\\n  Daulton doesn't strike me as all that strange. He's a little bit quiet at \\nthe plate but, like Franco, gets the bat through the hitting zone on a level\\nplane. The first time I watched Julio Franco, I didn't think *anyone* could\\nhit like that. Now I marvel at how easy he makes it look; every time he makes\\ncontact, it's *solid*. He's got good power to all fields and rarely is he\\ncaught not ready for a pitch. \\n\\n  I wonder if Phil Plantier had a severe bout with hemorrhoids and had to\\npractice his swing while 'on the throne'? :-) Sure looks like it :-) \\n\\n  How 'bout one to add to your list: Travis Fryman? The guy plants his front\\nfoot and seems to swing *across* his body. He generates a lot of power, but\\nI keep thinking he could generate even more if he could get a better pivot\\nout of his hips. \\n\\n\\n  Well, they're already spoken for (by several people), but .. \\n\\n  I'd add Robbie Alomar's name to the list, among others. I really like Dean\\nPalmer's swing, for some twisted reason, as well as Pedro Munoz's swing. \\n\\n\\n  A thought about May: It looks like they've taught him to turn on the ball.\\nIMHO, he's going to fall in love with his newfound power and start pulling\\noff the ball to the point that he's going to see *lots* of sinkers/sliders\\nlow and away. Unless he adjusts quickly and starts rifling doubles to left \\nand left-center, IMHO you're going to see a good number of weak grounders to \\nthe right side of the infield in the next month. \\n</td>\n",
       "      <td>9</td>\n",
       "      <td>rec.sport.baseball</td>\n",
       "      <td>Ah, so you finally found a use for that super slo-mo and frame advance other than scrutinizing \"Sorority Babes in Heat\". Congrats! Trust me, you'd have a helluva time manipulating them. Besides, if you converted the film to video you'd have all kinds of artifacts because of the difference in frame rate (unless you're an expert at doing 3/2 pulldown for a laserdisc company or something). Hey, no fair! What about 'Fettucine' Alfredo Griffin? The guy practically has to pivot the bat around along with his body. Daulton doesn't strike me as all that strange. He's a little bit quiet at the plate but, like Franco, gets the bat through the hitting zone on a level plane. The first time I watched Julio Franco, I didn't think *anyone* could hit like that. Now I marvel at how easy he makes it look; every time he makes contact, it's *solid*. He's got good power to all fields and rarely is he caught not ready for a pitch. I wonder if Phil Plantier had a severe bout with hemorrhoids and had to practice his swing while 'on the throne'? :-) Sure looks like it :-) How 'bout one to add to your list: Travis Fryman? The guy plants his front foot and seems to swing *across* his body. He generates a lot of power, but I keep thinking he could generate even more if he could get a better pivot out of his hips. Well, they're already spoken for (by several people), but .. I'd add Robbie Alomar's name to the list, among others. I really like Dean Palmer's swing, for some twisted reason, as well as Pedro Munoz's swing. A thought about May: It looks like they've taught him to turn on the ball. IMHO, he's going to fall in love with his newfound power and start pulling off the ball to the point that he's going to see *lots* of sinkers/sliders low and away. Unless he adjusts quickly and starts rifling doubles to left and left-center, IMHO you're going to see a good number of weak grounders to the right side of the infield in the next month.</td>\n",
       "      <td>[\\n  , ah, finally, find, use, super, slo, mo, frame, advance, \\n, scrutinize, Sorority, Babes, Heat, Congrats, \\n\\n\\n  , trust, helluva, time, manipulate, \\n, convert, film, video, kind, artifact, \\n, difference, frame, rate, expert, 3/2, pulldown, \\n, laserdisc, company, \\n\\n\\n  , hey, fair, Fettucine, Alfredo, Griffin, guy, practically, \\n, pivot, bat, body, \\n\\n\\n  , Daulton, strike, strange, little, bit, quiet, \\n, plate, like, Franco, get, bat, hit, zone, level, \\n, plane, time, watch, Julio, Franco, think, \\n, hit, like, marvel, easy, make, look, time, make, \\n, contact, solid, get, good, power, field, rarely, \\n, catch, ready, pitch, \\n\\n  , wonder, Phil, Plantier, severe, bout, hemorrhoid, ...]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            content  \\\n",
       "11241      I heard FASTMicro went out of business.  Is this true?  \\nThey don't answer their 800 number.  It's 800-821-9000.\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
       "9167   \\n\\nThe down side is that when I'm in my cage, I have on numerous occasions\\nslammed my hand into the rolled up window in an effort to wave at\\na passing biker.  Ow.\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
       "1461   \\n  Ah, so you finally found a use for that super slo-mo and frame advance\\nother than scrutinizing \"Sorority Babes in Heat\". Congrats! \\n\\n\\n  Trust me, you'd have a helluva time manipulating them. Besides, if you\\nconverted the film to video you'd have all kinds of artifacts because of the\\ndifference in frame rate (unless you're an expert at doing 3/2 pulldown for\\na laserdisc company or something). \\n\\n\\n  Hey, no fair! What about 'Fettucine' Alfredo Griffin? The guy practically\\nhas to pivot the bat around along with his body. \\n\\n\\n  Daulton doesn't strike me as all that strange. He's a little bit quiet at \\nthe plate but, like Franco, gets the bat through the hitting zone on a level\\nplane. The first time I watched Julio Franco, I didn't think *anyone* could\\nhit like that. Now I marvel at how easy he makes it look; every time he makes\\ncontact, it's *solid*. He's got good power to all fields and rarely is he\\ncaught not ready for a pitch. \\n\\n  I wonder if Phil Plantier had a severe bout with hemorrhoids and had to\\npractice his swing while 'on the throne'? :-) Sure looks like it :-) \\n\\n  How 'bout one to add to your list: Travis Fryman? The guy plants his front\\nfoot and seems to swing *across* his body. He generates a lot of power, but\\nI keep thinking he could generate even more if he could get a better pivot\\nout of his hips. \\n\\n\\n  Well, they're already spoken for (by several people), but .. \\n\\n  I'd add Robbie Alomar's name to the list, among others. I really like Dean\\nPalmer's swing, for some twisted reason, as well as Pedro Munoz's swing. \\n\\n\\n  A thought about May: It looks like they've taught him to turn on the ball.\\nIMHO, he's going to fall in love with his newfound power and start pulling\\noff the ball to the point that he's going to see *lots* of sinkers/sliders\\nlow and away. Unless he adjusts quickly and starts rifling doubles to left \\nand left-center, IMHO you're going to see a good number of weak grounders to \\nthe right side of the infield in the next month. \\n   \n",
       "\n",
       "       target              target_names  \\\n",
       "11241  3       comp.sys.ibm.pc.hardware   \n",
       "9167   8       rec.motorcycles            \n",
       "1461   9       rec.sport.baseball         \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 clean_text  \\\n",
       "11241  I heard FASTMicro went out of business. Is this true? They don't answer their 800 number. It's 800-821-9000.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
       "9167   The down side is that when I'm in my cage, I have on numerous occasions slammed my hand into the rolled up window in an effort to wave at a passing biker. Ow.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
       "1461   Ah, so you finally found a use for that super slo-mo and frame advance other than scrutinizing \"Sorority Babes in Heat\". Congrats! Trust me, you'd have a helluva time manipulating them. Besides, if you converted the film to video you'd have all kinds of artifacts because of the difference in frame rate (unless you're an expert at doing 3/2 pulldown for a laserdisc company or something). Hey, no fair! What about 'Fettucine' Alfredo Griffin? The guy practically has to pivot the bat around along with his body. Daulton doesn't strike me as all that strange. He's a little bit quiet at the plate but, like Franco, gets the bat through the hitting zone on a level plane. The first time I watched Julio Franco, I didn't think *anyone* could hit like that. Now I marvel at how easy he makes it look; every time he makes contact, it's *solid*. He's got good power to all fields and rarely is he caught not ready for a pitch. I wonder if Phil Plantier had a severe bout with hemorrhoids and had to practice his swing while 'on the throne'? :-) Sure looks like it :-) How 'bout one to add to your list: Travis Fryman? The guy plants his front foot and seems to swing *across* his body. He generates a lot of power, but I keep thinking he could generate even more if he could get a better pivot out of his hips. Well, they're already spoken for (by several people), but .. I'd add Robbie Alomar's name to the list, among others. I really like Dean Palmer's swing, for some twisted reason, as well as Pedro Munoz's swing. A thought about May: It looks like they've taught him to turn on the ball. IMHO, he's going to fall in love with his newfound power and start pulling off the ball to the point that he's going to see *lots* of sinkers/sliders low and away. Unless he adjusts quickly and starts rifling doubles to left and left-center, IMHO you're going to see a good number of weak grounders to the right side of the infield in the next month.   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         lemmas  \n",
       "11241  [    , hear, FASTMicro, go, business,  , true,  \\n, answer, 800, number,  , 800, 821, 9000, \\n]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
       "9167   [\\n\\n, cage, numerous, occasion, \\n, slam, hand, roll, window, effort, wave, \\n, pass, biker,  , ow, \\n]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "1461   [\\n  , ah, finally, find, use, super, slo, mo, frame, advance, \\n, scrutinize, Sorority, Babes, Heat, Congrats, \\n\\n\\n  , trust, helluva, time, manipulate, \\n, convert, film, video, kind, artifact, \\n, difference, frame, rate, expert, 3/2, pulldown, \\n, laserdisc, company, \\n\\n\\n  , hey, fair, Fettucine, Alfredo, Griffin, guy, practically, \\n, pivot, bat, body, \\n\\n\\n  , Daulton, strike, strange, little, bit, quiet, \\n, plate, like, Franco, get, bat, hit, zone, level, \\n, plane, time, watch, Julio, Franco, think, \\n, hit, like, marvel, easy, make, look, time, make, \\n, contact, solid, get, good, power, field, rarely, \\n, catch, ready, pitch, \\n\\n  , wonder, Phil, Plantier, severe, bout, hemorrhoid, ...]  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kSW10Cb33Lzk"
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pkgfv9tc3Lzi"
   },
   "outputs": [],
   "source": [
    "# Leverage tqdm for progress_apply\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "# If you're on macOS, Linux, or python session executed from Windows Subsystem for Linux (WSL)\n",
    "# conda activate U4-S1-NLP\n",
    "# pip install pandarallel\n",
    "#\n",
    "# from pandarallel import pandarallel\n",
    "# pandarallel.initialize(progress_bar=True)\n",
    "#\n",
    "# df['lemmas'] = df['content'].parallel_apply(get_lemmas)\n",
    "#\n",
    "# Ref: https://github.com/nalepae/pandarallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6EBPQXqEKE9P"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 11314/11314 [06:31<00:00, 28.89it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create 'lemmas' column\n",
    "def get_lemmas(x):\n",
    "    lemmas = []\n",
    "    for token in nlp(x):\n",
    "        if (token.is_stop!=True) and (token.is_punct!=True):\n",
    "            lemmas.append(token.lemma_)\n",
    "    return lemmas\n",
    "\n",
    "df['lemmas'] = df['clean_text'].progress_apply(get_lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-yvsyIpvKBlw"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>target</th>\n",
       "      <th>target_names</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I was wondering if anyone out there could enlighten me on this car I saw\\nthe other day. It was a 2-door sports car, looked to be from the late 60s/\\nearly 70s. It was called a Bricklin. The doors were really small. In addition,\\nthe front bumper was separate from the rest of the body. This is \\nall I know. If anyone can tellme a model name, engine specs, years\\nof production, where this car is made, history, or whatever info you\\nhave on this funky looking car, please e-mail.</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>I was wondering if anyone out there could enlighten me on this car I saw the other day. It was a 2-door sports car, looked to be from the late 60s/ early 70s. It was called a Bricklin. The doors were really small. In addition, the front bumper was separate from the rest of the body. This is all I know. If anyone can tellme a model name, engine specs, years of production, where this car is made, history, or whatever info you have on this funky looking car, please e-mail.</td>\n",
       "      <td>[wonder, enlighten, car, see, day, 2-door, sport, car, look, late, 60s/, early, 70, call, Bricklin, door, small, addition, bumper, separate, rest, body, know, tellme, model, engine, spec, year, production, car, history, info, funky, look, car, e, mail]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A fair number of brave souls who upgraded their SI clock oscillator have\\nshared their experiences for this poll. Please send a brief message detailing\\nyour experiences with the procedure. Top speed attained, CPU rated speed,\\nadd on cards and adapters, heat sinks, hour of usage per day, floppy disk\\nfunctionality with 800 and 1.4 m floppies are especially requested.\\n\\nI will be summarizing in the next two days, so please add to the network\\nknowledge base if you have done the clock upgrade and haven't answered this\\npoll. Thanks.</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "      <td>A fair number of brave souls who upgraded their SI clock oscillator have shared their experiences for this poll. Please send a brief message detailing your experiences with the procedure. Top speed attained, CPU rated speed, add on cards and adapters, heat sinks, hour of usage per day, floppy disk functionality with 800 and 1.4 m floppies are especially requested. I will be summarizing in the next two days, so please add to the network knowledge base if you have done the clock upgrade and haven't answered this poll. Thanks.</td>\n",
       "      <td>[fair, number, brave, soul, upgrade, SI, clock, oscillator, share, experience, poll, send, brief, message, detail, experience, procedure, speed, attain, CPU, rate, speed, add, card, adapter, heat, sink, hour, usage, day, floppy, disk, functionality, 800, 1.4, m, floppy, especially, request, summarize, day, add, network, knowledge, base, clock, upgrade, answer, poll, thank]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>well folks, my mac plus finally gave up the ghost this weekend after\\nstarting life as a 512k way back in 1985.  sooo, i'm in the market for a\\nnew machine a bit sooner than i intended to be...\\n\\ni'm looking into picking up a powerbook 160 or maybe 180 and have a bunch\\nof questions that (hopefully) somebody can answer:\\n\\n* does anybody know any dirt on when the next round of powerbook\\nintroductions are expected?  i'd heard the 185c was supposed to make an\\nappearence \"this summer\" but haven't heard anymore on it - and since i\\ndon't have access to macleak, i was wondering if anybody out there had\\nmore info...\\n\\n* has anybody heard rumors about price drops to the powerbook line like the\\nones the duo's just went through recently?\\n\\n* what's the impression of the display on the 180?  i could probably swing\\na 180 if i got the 80Mb disk rather than the 120, but i don't really have\\na feel for how much \"better\" the display is (yea, it looks great in the\\nstore, but is that all \"wow\" or is it really that good?).  could i solicit\\nsome opinions of people who use the 160 and 180 day-to-day on if its worth\\ntaking the disk size and money hit to get the active display?  (i realize\\nthis is a real subjective question, but i've only played around with the\\nmachines in a computer store breifly and figured the opinions of somebody\\nwho actually uses the machine daily might prove helpful).\\n\\n* how well does hellcats perform?  ;)\\n\\nthanks a bunch in advance for any info - if you could email, i'll post a\\nsummary (news reading time is at a premium with finals just around the\\ncorner... :( )\\n--\\nTom Willis  \\  twillis@ecn.purdue.edu    \\    Purdue Electrical Engineering</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "      <td>well folks, my mac plus finally gave up the ghost this weekend after starting life as a 512k way back in 1985. sooo, i'm in the market for a new machine a bit sooner than i intended to be... i'm looking into picking up a powerbook 160 or maybe 180 and have a bunch of questions that (hopefully) somebody can answer: * does anybody know any dirt on when the next round of powerbook introductions are expected? i'd heard the 185c was supposed to make an appearence \"this summer\" but haven't heard anymore on it - and since i don't have access to macleak, i was wondering if anybody out there had more info... * has anybody heard rumors about price drops to the powerbook line like the ones the duo's just went through recently? * what's the impression of the display on the 180? i could probably swing a 180 if i got the 80Mb disk rather than the 120, but i don't really have a feel for how much \"better\" the display is (yea, it looks great in the store, but is that all \"wow\" or is it really that good?). could i solicit some opinions of people who use the 160 and 180 day-to-day on if its worth taking the disk size and money hit to get the active display? (i realize this is a real subjective question, but i've only played around with the machines in a computer store breifly and figured the opinions of somebody who actually uses the machine daily might prove helpful). * how well does hellcats perform? ;) thanks a bunch in advance for any info - if you could email, i'll post a summary (news reading time is at a premium with finals just around the corner... :( ) -- Tom Willis \\ twillis@ecn.purdue.edu \\ Purdue Electrical Engineering</td>\n",
       "      <td>[folk, mac, plus, finally, give, ghost, weekend, start, life, 512k, way, 1985, sooo, market, new, machine, bit, sooner, intend, look, pick, powerbook, 160, maybe, 180, bunch, question, hopefully, somebody, answer, anybody, know, dirt, round, powerbook, introduction, expect, hear, 185c, suppose, appearence, summer, hear, anymore, access, macleak, wonder, anybody, info, anybody, hear, rumor, price, drop, powerbook, line, like, one, duo, go, recently, impression, display, 180, probably, swing, 180, get, 80mb, disk, 120, feel, well, display, yea, look, great, store, wow, good, solicit, opinion, people, use, 160, 180, day, day, worth, take, disk, size, money, hit, active, display, realize, real, subjective, question, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nDo you have Weitek's address/phone number?  I'd like to get some information\\nabout this chip.\\n</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "      <td>Do you have Weitek's address/phone number? I'd like to get some information about this chip.</td>\n",
       "      <td>[Weitek, address, phone, number, like, information, chip]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From article &lt;C5owCB.n3p@world.std.com&gt;, by tombaker@world.std.com (Tom A Baker):\\n\\n\\nMy understanding is that the 'expected errors' are basically\\nknown bugs in the warning system software - things are checked\\nthat don't have the right values in yet because they aren't\\nset till after launch, and suchlike. Rather than fix the code\\nand possibly introduce new bugs, they just tell the crew\\n'ok, if you see a warning no. 213 before liftoff, ignore it'.</td>\n",
       "      <td>14</td>\n",
       "      <td>sci.space</td>\n",
       "      <td>From article &lt;C5owCB.n3p@world.std.com&gt;, by tombaker@world.std.com (Tom A Baker): My understanding is that the 'expected errors' are basically known bugs in the warning system software - things are checked that don't have the right values in yet because they aren't set till after launch, and suchlike. Rather than fix the code and possibly introduce new bugs, they just tell the crew 'ok, if you see a warning no. 213 before liftoff, ignore it'.</td>\n",
       "      <td>[article, &lt;, c5owcb.n3p@world.std.com, &gt;, tombaker@world.std.com, Tom, Baker, understanding, expect, error, basically, know, bug, warning, system, software, thing, check, right, value, set, till, launch, suchlike, fix, code, possibly, introduce, new, bug, tell, crew, ok, warning, 213, liftoff, ignore]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       content  \\\n",
       "0  I was wondering if anyone out there could enlighten me on this car I saw\\nthe other day. It was a 2-door sports car, looked to be from the late 60s/\\nearly 70s. It was called a Bricklin. The doors were really small. In addition,\\nthe front bumper was separate from the rest of the body. This is \\nall I know. If anyone can tellme a model name, engine specs, years\\nof production, where this car is made, history, or whatever info you\\nhave on this funky looking car, please e-mail.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "1  A fair number of brave souls who upgraded their SI clock oscillator have\\nshared their experiences for this poll. Please send a brief message detailing\\nyour experiences with the procedure. Top speed attained, CPU rated speed,\\nadd on cards and adapters, heat sinks, hour of usage per day, floppy disk\\nfunctionality with 800 and 1.4 m floppies are especially requested.\\n\\nI will be summarizing in the next two days, so please add to the network\\nknowledge base if you have done the clock upgrade and haven't answered this\\npoll. Thanks.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
       "2  well folks, my mac plus finally gave up the ghost this weekend after\\nstarting life as a 512k way back in 1985.  sooo, i'm in the market for a\\nnew machine a bit sooner than i intended to be...\\n\\ni'm looking into picking up a powerbook 160 or maybe 180 and have a bunch\\nof questions that (hopefully) somebody can answer:\\n\\n* does anybody know any dirt on when the next round of powerbook\\nintroductions are expected?  i'd heard the 185c was supposed to make an\\nappearence \"this summer\" but haven't heard anymore on it - and since i\\ndon't have access to macleak, i was wondering if anybody out there had\\nmore info...\\n\\n* has anybody heard rumors about price drops to the powerbook line like the\\nones the duo's just went through recently?\\n\\n* what's the impression of the display on the 180?  i could probably swing\\na 180 if i got the 80Mb disk rather than the 120, but i don't really have\\na feel for how much \"better\" the display is (yea, it looks great in the\\nstore, but is that all \"wow\" or is it really that good?).  could i solicit\\nsome opinions of people who use the 160 and 180 day-to-day on if its worth\\ntaking the disk size and money hit to get the active display?  (i realize\\nthis is a real subjective question, but i've only played around with the\\nmachines in a computer store breifly and figured the opinions of somebody\\nwho actually uses the machine daily might prove helpful).\\n\\n* how well does hellcats perform?  ;)\\n\\nthanks a bunch in advance for any info - if you could email, i'll post a\\nsummary (news reading time is at a premium with finals just around the\\ncorner... :( )\\n--\\nTom Willis  \\  twillis@ecn.purdue.edu    \\    Purdue Electrical Engineering   \n",
       "3  \\nDo you have Weitek's address/phone number?  I'd like to get some information\\nabout this chip.\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
       "4  From article <C5owCB.n3p@world.std.com>, by tombaker@world.std.com (Tom A Baker):\\n\\n\\nMy understanding is that the 'expected errors' are basically\\nknown bugs in the warning system software - things are checked\\nthat don't have the right values in yet because they aren't\\nset till after launch, and suchlike. Rather than fix the code\\nand possibly introduce new bugs, they just tell the crew\\n'ok, if you see a warning no. 213 before liftoff, ignore it'.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
       "\n",
       "   target           target_names  \\\n",
       "0  7       rec.autos               \n",
       "1  4       comp.sys.mac.hardware   \n",
       "2  4       comp.sys.mac.hardware   \n",
       "3  1       comp.graphics           \n",
       "4  14      sci.space               \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                clean_text  \\\n",
       "0  I was wondering if anyone out there could enlighten me on this car I saw the other day. It was a 2-door sports car, looked to be from the late 60s/ early 70s. It was called a Bricklin. The doors were really small. In addition, the front bumper was separate from the rest of the body. This is all I know. If anyone can tellme a model name, engine specs, years of production, where this car is made, history, or whatever info you have on this funky looking car, please e-mail.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
       "1  A fair number of brave souls who upgraded their SI clock oscillator have shared their experiences for this poll. Please send a brief message detailing your experiences with the procedure. Top speed attained, CPU rated speed, add on cards and adapters, heat sinks, hour of usage per day, floppy disk functionality with 800 and 1.4 m floppies are especially requested. I will be summarizing in the next two days, so please add to the network knowledge base if you have done the clock upgrade and haven't answered this poll. Thanks.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
       "2  well folks, my mac plus finally gave up the ghost this weekend after starting life as a 512k way back in 1985. sooo, i'm in the market for a new machine a bit sooner than i intended to be... i'm looking into picking up a powerbook 160 or maybe 180 and have a bunch of questions that (hopefully) somebody can answer: * does anybody know any dirt on when the next round of powerbook introductions are expected? i'd heard the 185c was supposed to make an appearence \"this summer\" but haven't heard anymore on it - and since i don't have access to macleak, i was wondering if anybody out there had more info... * has anybody heard rumors about price drops to the powerbook line like the ones the duo's just went through recently? * what's the impression of the display on the 180? i could probably swing a 180 if i got the 80Mb disk rather than the 120, but i don't really have a feel for how much \"better\" the display is (yea, it looks great in the store, but is that all \"wow\" or is it really that good?). could i solicit some opinions of people who use the 160 and 180 day-to-day on if its worth taking the disk size and money hit to get the active display? (i realize this is a real subjective question, but i've only played around with the machines in a computer store breifly and figured the opinions of somebody who actually uses the machine daily might prove helpful). * how well does hellcats perform? ;) thanks a bunch in advance for any info - if you could email, i'll post a summary (news reading time is at a premium with finals just around the corner... :( ) -- Tom Willis \\ twillis@ecn.purdue.edu \\ Purdue Electrical Engineering   \n",
       "3  Do you have Weitek's address/phone number? I'd like to get some information about this chip.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
       "4  From article <C5owCB.n3p@world.std.com>, by tombaker@world.std.com (Tom A Baker): My understanding is that the 'expected errors' are basically known bugs in the warning system software - things are checked that don't have the right values in yet because they aren't set till after launch, and suchlike. Rather than fix the code and possibly introduce new bugs, they just tell the crew 'ok, if you see a warning no. 213 before liftoff, ignore it'.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   lemmas  \n",
       "0  [wonder, enlighten, car, see, day, 2-door, sport, car, look, late, 60s/, early, 70, call, Bricklin, door, small, addition, bumper, separate, rest, body, know, tellme, model, engine, spec, year, production, car, history, info, funky, look, car, e, mail]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
       "1  [fair, number, brave, soul, upgrade, SI, clock, oscillator, share, experience, poll, send, brief, message, detail, experience, procedure, speed, attain, CPU, rate, speed, add, card, adapter, heat, sink, hour, usage, day, floppy, disk, functionality, 800, 1.4, m, floppy, especially, request, summarize, day, add, network, knowledge, base, clock, upgrade, answer, poll, thank]                                                                                                                                                                                                                                                                                                                                                                 \n",
       "2  [folk, mac, plus, finally, give, ghost, weekend, start, life, 512k, way, 1985, sooo, market, new, machine, bit, sooner, intend, look, pick, powerbook, 160, maybe, 180, bunch, question, hopefully, somebody, answer, anybody, know, dirt, round, powerbook, introduction, expect, hear, 185c, suppose, appearence, summer, hear, anymore, access, macleak, wonder, anybody, info, anybody, hear, rumor, price, drop, powerbook, line, like, one, duo, go, recently, impression, display, 180, probably, swing, 180, get, 80mb, disk, 120, feel, well, display, yea, look, great, store, wow, good, solicit, opinion, people, use, 160, 180, day, day, worth, take, disk, size, money, hit, active, display, realize, real, subjective, question, ...]  \n",
       "3  [Weitek, address, phone, number, like, information, chip]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
       "4  [article, <, c5owcb.n3p@world.std.com, >, tombaker@world.std.com, Tom, Baker, understanding, expect, error, basically, know, bug, warning, system, software, thing, check, right, value, set, till, launch, suchlike, fix, code, possibly, introduce, new, bug, tell, crew, ok, warning, 213, liftoff, ignore]                                                                                                                                                                                                                                                                                                                                                                                                                                          "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cPuCuK0z3Lzs"
   },
   "source": [
    "### The two main inputs to the LDA topic model are the dictionary (id2word) and the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1klqRpqtJxWc"
   },
   "outputs": [],
   "source": [
    "# Create Dictionary - Maps a number to a word\n",
    "id2word = corpora.Dictionary(df['lemmas'] )\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in df['lemmas']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117191"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many words do we have?\n",
    "len(id2word.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's remove extreme values from the dataset\n",
    "id2word.filter_extremes(no_below=5, no_above=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14653"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many words do we have?\n",
    "len(id2word.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ArZPxcP5LH1J"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Engineering'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2word[76]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_IIBnI2e3Lzw"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Of course. The term must be rigidly defined in any bill. I doubt she uses this term for that. You are using a quote allegedly from her, can you back it up? I read the article as presenting first an argument about weapons of mass destruction (as commonly understood) and then switching to other topics. The first point evidently was to show that not all weapons should be allowed, and then the later analysis was, given this understanding, to consider another class.'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_text'][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bGFG9E2j3Lzz"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(112, 1),\n",
       " (170, 1),\n",
       " (186, 1),\n",
       " (210, 1),\n",
       " (213, 1),\n",
       " (214, 1),\n",
       " (215, 1),\n",
       " (216, 1),\n",
       " (217, 1),\n",
       " (218, 1),\n",
       " (219, 1),\n",
       " (220, 1),\n",
       " (221, 1),\n",
       " (222, 1),\n",
       " (223, 1),\n",
       " (224, 1),\n",
       " (225, 1),\n",
       " (226, 1),\n",
       " (227, 1),\n",
       " (228, 1),\n",
       " (229, 1),\n",
       " (230, 1),\n",
       " (231, 1),\n",
       " (232, 1),\n",
       " (233, 1),\n",
       " (234, 2),\n",
       " (235, 1),\n",
       " (236, 1),\n",
       " (237, 2)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TB6wox963Lz2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'40mb'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2word[252]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kk3g75XX3Lz4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fact'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2word[276]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6K2jWxHJLOzK"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('impression', 1),\n",
       " ('213', 1),\n",
       " ('ok', 1),\n",
       " ('evidently', 1),\n",
       " ('point', 1),\n",
       " ('present', 1),\n",
       " ('quote', 1),\n",
       " ('read', 1),\n",
       " ('switch', 1),\n",
       " ('term', 1),\n",
       " ('topic', 1),\n",
       " ('understand', 1),\n",
       " ('weapon', 1),\n",
       " ('Sean', 1),\n",
       " ('September', 1),\n",
       " ('Sharon', 1),\n",
       " ('accidentally', 1),\n",
       " ('bounce', 1),\n",
       " ('delete', 1),\n",
       " ('directly', 1),\n",
       " ('file', 1),\n",
       " ('glad', 1),\n",
       " ('hmmm', 1),\n",
       " ('instead', 1),\n",
       " ('publicly', 1),\n",
       " ('respond', 2),\n",
       " ('rm', 1),\n",
       " ('rn', 1),\n",
       " ('sure', 2)]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Human readable format of corpus (term-frequency)\n",
    "[(id2word[word_id], word_count) for word_id, word_count in corpus[5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "le-XzI923Lz8"
   },
   "source": [
    "# Part 2: Estimate a LDA Model with Gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AlNG4bSI3Lz8"
   },
   "source": [
    " ### Train an LDA model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fasvjf0VLQ2a"
   },
   "source": [
    "%%time\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                            id2word=id2word,\n",
    "                                            num_topics=20, \n",
    "                                            chunksize=100,\n",
    "                                            passes=10,\n",
    "                                            per_word_topics=True)\n",
    "\n",
    "# https://radimrehurek.com/gensim/models/ldamodel.html"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "49CabmIj3Lz_"
   },
   "source": [
    "# lda_model.save('lda_model.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XDgUshRE3L0C"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\U4-S1-NLP\\lib\\site-packages\\gensim\\models\\ldamulticore.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, corpus, num_topics, id2word, workers, chunksize, passes, batch, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, random_state, minimum_probability, minimum_phi_value, per_word_topics, dtype)\u001b[0m\n\u001b[0;32m    177\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"auto-tuning alpha not implemented in multicore LDA; use plain LdaModel.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 179\u001b[1;33m         super(LdaMulticore, self).__init__(\n\u001b[0m\u001b[0;32m    180\u001b[0m             \u001b[0mcorpus\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_topics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_topics\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m             \u001b[0mid2word\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mid2word\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpasses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpasses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meta\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\U4-S1-NLP\\lib\\site-packages\\gensim\\models\\ldamodel.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, corpus, num_topics, id2word, distributed, chunksize, passes, update_every, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, minimum_probability, random_state, ns_conf, minimum_phi_value, per_word_topics, callbacks, dtype)\u001b[0m\n\u001b[0;32m    517\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m             \u001b[0muse_numpy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatcher\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 519\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunks_as_numpy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_numpy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    520\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minit_dir_prior\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprior\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\U4-S1-NLP\\lib\\site-packages\\gensim\\models\\ldamulticore.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, corpus, chunks_as_numpy)\u001b[0m\n\u001b[0;32m    308\u001b[0m             \u001b[1;31m# wait for all outstanding jobs to finish\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[0mqueue_size\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 310\u001b[1;33m                 \u001b[0mprocess_result_queue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mforce\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    311\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mreallen\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlencorpus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\U4-S1-NLP\\lib\\site-packages\\gensim\\models\\ldamulticore.py\u001b[0m in \u001b[0;36mprocess_result_queue\u001b[1;34m(force)\u001b[0m\n\u001b[0;32m    266\u001b[0m             \"\"\"\n\u001b[0;32m    267\u001b[0m             \u001b[0mmerged_new\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 268\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mresult_queue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    269\u001b[0m                 \u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult_queue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m                 \u001b[0mqueue_size\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\U4-S1-NLP\\lib\\multiprocessing\\queues.py\u001b[0m in \u001b[0;36mempty\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\U4-S1-NLP\\lib\\multiprocessing\\connection.py\u001b[0m in \u001b[0;36mpoll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\U4-S1-NLP\\lib\\multiprocessing\\connection.py\u001b[0m in \u001b[0;36m_poll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    326\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m             if (self._got_empty_message or\n\u001b[1;32m--> 328\u001b[1;33m                         _winapi.PeekNamedPipe(self._handle)[0] != 0):\n\u001b[0m\u001b[0;32m    329\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lda_multicore = gensim.models.ldamulticore.LdaMulticore(corpus=corpus,\n",
    "                                                        id2word=id2word,\n",
    "                                                        num_topics=20, \n",
    "                                                        chunksize=100,\n",
    "                                                        passes=10,\n",
    "                                                        per_word_topics=True,\n",
    "                                                        workers=12)\n",
    "\n",
    "# https://radimrehurek.com/gensim/models/ldamulticore.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rgb9AaPq3L0E"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lda_multicore' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-d583ef74a940>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlda_multicore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'lda_multicore.model'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'lda_multicore' is not defined"
     ]
    }
   ],
   "source": [
    "lda_multicore.save('lda_multicore.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VLxvJPoK3L0G"
   },
   "outputs": [],
   "source": [
    "from gensim import models\n",
    "lda_multicore =  models.LdaModel.load('lda_multicore.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uDH3tzx13L0I"
   },
   "source": [
    "### View the topics in LDA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroups_train.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JawR8yscLVNS"
   },
   "outputs": [],
   "source": [
    "# Prints the top 10 words in each topic\n",
    "pprint(lda_multicore.print_topics())\n",
    "doc_lda = lda_multicore[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distro = [lda[d] for d in corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gKEP0bIC3L0K"
   },
   "source": [
    "### What is topic Perplexity?\n",
    "Perplexity is a statistical measure of how well a probability model predicts a sample. As applied to LDA, for a given value of , you estimate the LDA model. Then given the theoretical word distributions represented by the topics, compare that to the actual topic mixtures, or distribution of words in your documents.\n",
    "\n",
    "### What is topic coherence?\n",
    "Topic Coherence measures score a single topic by measuring the degree of semantic similarity between high scoring words in the topic. These measurements help distinguish between topics that are semantically interpretable topics and topics that are artifacts of statistical inference.\n",
    "A set of statements or facts is said to be coherent, if they support each other. Thus, a coherent fact set can be interpreted in a context that covers all or most of the facts. An example of a coherent fact set is “the game is a team sport”, “the game is played with a ball”, “the game demands great physical efforts”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xCjhr8k4LXSy"
   },
   "outputs": [],
   "source": [
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', lda_multicore.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_multicore, \n",
    "                                     texts=df['lemmas'], \n",
    "                                     dictionary=id2word, \n",
    "                                     coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7UvfgYt93L0X"
   },
   "source": [
    "# Part 3: Interpret LDA results & Select the appropriate number of topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CYXi480VLaHK"
   },
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda_multicore, corpus, id2word)\n",
    "pyLDAvis.display(vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rjtXk8J3LaXC"
   },
   "outputs": [],
   "source": [
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = gensim.models.ldamulticore.LdaMulticore(corpus=corpus,\n",
    "                                                        id2word=id2word,\n",
    "                                                        num_topics=num_topics, \n",
    "                                                        chunksize=100,\n",
    "                                                        passes=10,\n",
    "                                                        per_word_topics=True,\n",
    "                                                        workers=12)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pRA9EjvQ3L0c"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "model_list, coherence_values = compute_coherence_values(dictionary=id2word, \n",
    "                                                        corpus=corpus, \n",
    "                                                        texts=df['lemmas'], \n",
    "                                                        start=2, \n",
    "                                                        limit=40, \n",
    "                                                        step=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2e9X-Ql-3L0e"
   },
   "outputs": [],
   "source": [
    "coherence_values = [0.5054, 0.5332, 0.5452, 0.564, 0.5678, 0.5518, 0.519]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ybEBYQNF3L0g"
   },
   "outputs": [],
   "source": [
    "limit=40; start=2; step=6;\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DmvQ2zKZ3L0i"
   },
   "outputs": [],
   "source": [
    "# Print the coherence scores\n",
    "for m, cv in zip(x, coherence_values):\n",
    "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yol5vG3R3L0k"
   },
   "outputs": [],
   "source": [
    "# Select the model and print the topics\n",
    "#optimal_model = model_list[4]\n",
    "optimal_model =  models.LdaModel.load('optimal_model.model')\n",
    "model_topics = optimal_model.show_topics(formatted=False)\n",
    "pprint(optimal_model.print_topics(num_words=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8HwVEUDI3L0m"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DSPT6_LS_DS_414_Topic_Modeling.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "u4-s1-NLP (Python 3)",
   "language": "python",
   "name": "u4-s1-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
